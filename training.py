# from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torch.nn.functional as F
from torch.autograd import Variable 


###keras
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.utils import to_categorical

keypoints_dir = './data/keypoints/'  # define keypoints directory
frames_to_sample_per_vid = 20 #specify number of frames we want to sample from each video
holistic = True
input_dim = 1662 if holistic else 132

def generate_split_data(split, label_map, holistic=True):
    mp_dir = 'holistic' #if holistic else 'pose' # figuring out which keypoint directory to look in
    y_labels = [] # ground truth labels
    split_vids = [] # list of all (num_frames,num_keypoints) video npy arrays
    split_dir = f"{keypoints_dir}{mp_dir}/{split}/"

    # iterate through all available video npy arrays for this particular split
    for npy_name in os.listdir(split_dir):
        if npy_name != '.DS_Store':
            f = os.path.join(split_dir, npy_name)
            
            # sample frames_to_sample_per_vid consecutive frames from this array, since vids have diff lengths
            vid_kp_npy = np.load(f)[:,:input_dim]

            vid_kp = pd.DataFrame(vid_kp_npy).sample(frames_to_sample_per_vid).sort_index().reset_index(drop=True) 

            # extract gloss from the name of the .npy file
            vid_gloss = npy_name.split('_')[1].split('.')[0]

            split_vids.append(vid_kp)
            y_labels.append(label_map[vid_gloss])

    X = np.array(split_vids)
    y = np.array(y_labels)

    # return torch.tensor(X), torch.tensor(y).type(torch.LongTensor) #for pytorch models
    return X, y #- TODO: uncomment this for pytorch training
    
def main():
    glosses_to_test = list(np.load("glosses_to_test.npy")) #read in npy file listing glosses we're testing - generated by running video_preprocessing.py
    num_glosses = len(glosses_to_test)

    gloss_label_map = {label:num for num, label in enumerate(glosses_to_test)}

    # generating X,y data per split type
    X_train, y_train = generate_split_data('train', gloss_label_map, holistic=holistic)
    X_test, y_test = generate_split_data('test', gloss_label_map, holistic=holistic)
    X_val, y_val = generate_split_data('val', gloss_label_map, holistic=holistic)

    # transforming labels to one hot vector representation
    y_train_ctg = to_categorical(y_train, num_glosses).astype(int) 
    y_test_ctg = to_categorical(y_test, num_glosses).astype(int)
    y_val_ctg = to_categorical(y_val, num_glosses).astype(int)

### Keras LSTM model training
    model = Sequential()
    model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(frames_to_sample_per_vid,input_dim)))
    model.add(LSTM(128, return_sequences=True, activation='relu'))
    model.add(LSTM(64, return_sequences=False, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(num_glosses, activation='softmax'))

    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
    model.fit(X_train, y_train_ctg, epochs=700)
    print(model.summary())

    # model.save('categorical_lstm.h5')
if __name__=="__main__":
    main()      
