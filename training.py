# from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import os
import matplotlib.pyplot as plt
import pandas as pd
import torch
import torch.nn as nn
import torch.optim as optim
import torch.utils.data as data
import torch.nn.functional as F
from torch.autograd import Variable 


###keras
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense
from tensorflow.keras.callbacks import TensorBoard
from tensorflow.keras.utils import to_categorical

gcn_input_dir = './data/gcn_input/'  # define gcn input directory
keypoints_dir = './data/keypoints/'  # define keypoints directory
frames_to_sample_per_vid = 20 #specify number of frames we want to sample from each video
holistic = True
input_dim = 1662 if holistic else 132

def generate_split_data(split, label_map, holistic=True, kp=True): #kp == True if we're generating training data from keypoints
    input_size = 1662 if holistic else 132
    mp_dir = 'holistic' #if holistic else 'pose' # figuring out which keypoint directory to look in
    y_labels = [] # ground truth labels
    split_vids = [] # list of all (num_frames,num_keypoints) video npy arrays
    frames_to_sample = 20 #specify number of frames we want to sample from each video
    split_dir = f"{keypoints_dir}{mp_dir}/{split}/" if kp else f"{gcn_input_dir}{mp_dir}/{split}/node_ft_mats"
    
    # iterate through all available video npy arrays for this particular split
    for npy_name in os.listdir(split_dir):
        if npy_name != '.DS_Store':
            f = os.path.join(split_dir, npy_name)
            
            if kp:
                # sample 20 consecutive frames from this array, since vids have diff lengths
                vid_npy = np.load(f)[:,:input_size]

                vid_npy = pd.DataFrame(vid_npy).sample(frames_to_sample).sort_index().reset_index(drop=True)
            else:
                vid_npy = pd.DataFrame(np.load(f))

            # extract gloss from the name of the .npy file
            vid_gloss = npy_name.split('_')[1].split('.')[0]

            split_vids.append(vid_npy)
            y_labels.append(label_map[vid_gloss])

    X = np.array(split_vids)
    y = np.array(y_labels)

    # return torch.tensor(X), torch.tensor(y).type(torch.LongTensor)
    return X, y
    
def LSTM_k(num_classes):
### Keras LSTM model training
    model = Sequential()
    model.add(LSTM(64, return_sequences=True, activation='relu', input_shape=(frames_to_sample_per_vid,input_dim)))
    model.add(LSTM(128, return_sequences=True, activation='relu'))
    model.add(LSTM(64, return_sequences=False, activation='relu'))
    model.add(Dense(64, activation='relu'))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))

    return model

def main():
    glosses_to_test = list(np.load("glosses_to_test.npy")) #read in npy file listing glosses we're testing - generated by running video_preprocessing.py
    num_glosses = len(glosses_to_test)

    gloss_label_map = {label:num for num, label in enumerate(glosses_to_test)}

    # generating X,y data per split type
    X_train, y_train = generate_split_data('train', gloss_label_map, holistic=holistic)
    X_test, y_test = generate_split_data('test', gloss_label_map, holistic=holistic)
    X_val, y_val = generate_split_data('val', gloss_label_map, holistic=holistic)

    # transforming labels to one hot vector representation
    y_train_ctg = to_categorical(y_train, num_glosses).astype(int) 
    y_test_ctg = to_categorical(y_test, num_glosses).astype(int)
    y_val_ctg = to_categorical(y_val, num_glosses).astype(int)

    model = LSTM_k(num_glosses)
    model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])
    model.fit(X_train, y_train_ctg, epochs=500)

    # Evaluate the model on the test data using `evaluate`
    print("Evaluate on test data")
    results = model.evaluate(X_test, y_test_ctg, batch_size=128)
    print("test loss, test acc:", results)

    # Generate predictions (probabilities -- the output of the last layer)
    # on new data using `predict`
    print("Generate predictions for 3 samples")
    predictions = model.predict(X_test[:3])
    print("predictions shape:", predictions.shape)

    print(model.summary())

    # model.save('categorical_lstm.h5')
if __name__=="__main__":
    main()      
